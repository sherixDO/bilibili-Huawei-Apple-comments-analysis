import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
from wordcloud import WordCloud
import jieba
import os


# --- 1. ç¯å¢ƒå‡†å¤‡ä¸æ•°æ®åŠ è½½ï¼ˆå·²æ›´æ–°å­—ä½“å¤„ç†å’Œå›¾ç‰‡ä¿å­˜é€»è¾‘ï¼‰ ---

# --- æ™ºèƒ½å­—ä½“è®¾ç½® ---
def set_chinese_font():
    """
    è®¾ç½®ä¸­æ–‡å­—ä½“ä¸ºåŒç›®å½•ä¸‹çš„ simhei.ttfã€‚
    è¿”å›å­—ä½“è·¯å¾„ï¼Œä¾› WordCloud ä½¿ç”¨ã€‚
    """
    font_path = 'simhei.ttf'
    if not os.path.exists(font_path):
        print(f"âŒ å­—ä½“æ–‡ä»¶ '{font_path}' ä¸å­˜åœ¨äºå½“å‰ç›®å½•ã€‚")
        print("è¯·ç¡®ä¿ simhei.ttf æ–‡ä»¶ä¸æ­¤è„šæœ¬åœ¨åŒä¸€æ–‡ä»¶å¤¹ä¸‹ã€‚")
        print("å›¾è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½æ— æ³•æ­£å¸¸æ˜¾ç¤ºã€‚")
        plt.rcParams['axes.unicode_minus'] = False
        return None

    try:
        # å°†å­—ä½“æ–‡ä»¶æ·»åŠ åˆ° matplotlib çš„å­—ä½“ç®¡ç†å™¨ä¸­ï¼Œä½¿å…¶å¯ä»¥æŒ‰åç§°æ‰¾åˆ°
        fm.fontManager.addfont(font_path)
        
        # è®¾ç½® matplotlib ä½¿ç”¨è¯¥å­—ä½“
        font_name = fm.FontProperties(fname=font_path).get_name()
        plt.rcParams['font.family'] = ['sans-serif']
        plt.rcParams['font.sans-serif'] = [font_name]
        plt.rcParams['axes.unicode_minus'] = False
        
        print(f"âœ… æˆåŠŸå°†å­—ä½“ '{font_name}' ({font_path}) æ·»åŠ åˆ° Matplotlib å¹¶è®¾ä¸ºé»˜è®¤ã€‚")
        return font_path
    except Exception as e:
        print(f"âš ï¸ åŠ è½½å­—ä½“ {font_path} å¤±è´¥: {e}")
        print("å›¾è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½æ— æ³•æ­£å¸¸æ˜¾ç¤ºã€‚")
        return None


# æ‰§è¡Œå­—ä½“è®¾ç½®ï¼Œå¹¶è·å–WordCloudæ‰€éœ€çš„å­—ä½“è·¯å¾„
CHINESE_FONT_PATH = set_chinese_font()

# æ£€æŸ¥å­—ä½“æ˜¯å¦æˆåŠŸè®¾ç½®
output_dir = 'output_images'
os.makedirs(output_dir, exist_ok=True)
print(f"æ‰€æœ‰å›¾ç‰‡å°†ä¿å­˜åœ¨ '{output_dir}' æ–‡ä»¶å¤¹ä¸­ã€‚")

# åŠ è½½æ•°æ®
huawei_df = pd.read_csv('huawei_analyzed_results.csv')
apple_df = pd.read_csv('apple_analyzed_results.csv')
huawei_df['brand'] = 'åä¸º'
apple_df['brand'] = 'è‹¹æœ'
combined_df = pd.concat([huawei_df, apple_df], ignore_index=True)

# --- 2. æ€»ä½“æƒ…æ„Ÿåˆ†å¸ƒå¯¹æ¯” ---
print("\n--- æ­£åœ¨ç”Ÿæˆæƒ…æ„Ÿåˆ†å¸ƒå¯¹æ¯”å›¾... ---")
sentiment_order = ['æ­£é¢', 'ä¸­æ€§', 'è´Ÿé¢']
plt.figure(figsize=(12, 6))
sns.countplot(data=combined_df, x='sentiment', hue='brand', order=sentiment_order, palette='viridis')
plt.title('åä¸º vs è‹¹æœ Bilibiliè¯„è®ºæƒ…æ„Ÿåˆ†å¸ƒå¯¹æ¯”', fontsize=16)
plt.xlabel('æƒ…æ„Ÿç±»åˆ«', fontsize=12)
plt.ylabel('è¯„è®ºæ•°é‡', fontsize=12)
plt.legend(title='æ‰‹æœºå“ç‰Œ')
plt.grid(axis='y', linestyle='--', alpha=0.7)
# ä¿å­˜å›¾ç‰‡
plt.savefig(os.path.join(output_dir, '1_sentiment_distribution_bar.png'), dpi=300, bbox_inches='tight')
plt.show()

fig, axes = plt.subplots(1, 2, figsize=(14, 7))
huawei_sentiment_counts = huawei_df['sentiment'].value_counts()
axes[0].pie(huawei_sentiment_counts, labels=huawei_sentiment_counts.index, autopct='%1.1f%%', startangle=140,
            colors=sns.color_palette('viridis', n_colors=len(huawei_sentiment_counts)))
axes[0].set_title('åä¸ºè¯„è®ºæƒ…æ„Ÿåˆ†å¸ƒ', fontsize=16)
apple_sentiment_counts = apple_df['sentiment'].value_counts()
axes[1].pie(apple_sentiment_counts, labels=apple_sentiment_counts.index, autopct='%1.1f%%', startangle=140,
            colors=sns.color_palette('viridis', n_colors=len(apple_sentiment_counts)))
axes[1].set_title('è‹¹æœè¯„è®ºæƒ…æ„Ÿåˆ†å¸ƒ', fontsize=16)
plt.suptitle('åä¸ºä¸è‹¹æœè¯„è®ºæƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾', fontsize=20)
# ä¿å­˜å›¾ç‰‡
plt.savefig(os.path.join(output_dir, '2_sentiment_distribution_pie.png'), dpi=300, bbox_inches='tight')
plt.show()

# --- 3. é«˜èµè¯„è®ºåˆ†æ ---
# (è¿™éƒ¨åˆ†æ˜¯æ–‡æœ¬è¾“å‡ºï¼Œä¸éœ€è¦ä¿å­˜å›¾ç‰‡)
print("\n--- æ­£åœ¨åˆ†æé«˜èµè¯„è®º... ---")


def display_top_comments(df, brand_name, sentiment, n=3):
    print(f"\n--- {brand_name} | {sentiment}æƒ…ç»ª | ç‚¹èµæ•° TOP {n} è¯„è®º ---")
    top_comments = df[(df['brand'] == brand_name) & (df['sentiment'] == sentiment)].nlargest(n, 'like_count')
    if top_comments.empty:
        print("æ— è¯¥ç±»åˆ«çš„è¯„è®ºã€‚")
        return
    for index, row in top_comments.iterrows():
        print(f"ğŸ‘ ç‚¹èµæ•°: {row['like_count']}")
        print(f"ğŸ’¬ è¯„è®ºå†…å®¹: {row['content']}")
        print(f"ğŸ¤– åˆ†æåŸå› : {row['reason']}\n")


display_top_comments(combined_df, 'åä¸º', 'æ­£é¢')
display_top_comments(combined_df, 'åä¸º', 'è´Ÿé¢')
display_top_comments(combined_df, 'è‹¹æœ', 'æ­£é¢')
display_top_comments(combined_df, 'è‹¹æœ', 'è´Ÿé¢')

# --- 4. ç‚¹èµæ•°ä¸æƒ…æ„Ÿå€¾å‘å…³ç³» ---
print("\n--- æ­£åœ¨ç”Ÿæˆç‚¹èµæ•°ä¸æƒ…æ„Ÿå…³ç³»ç®±å½¢å›¾... ---")
plt.figure(figsize=(14, 8))
sns.boxplot(data=combined_df, x='sentiment', y='like_count', hue='brand', order=sentiment_order, palette='Set2')
plt.yscale('log')
plt.title('ä¸åŒæƒ…æ„Ÿè¯„è®ºçš„ç‚¹èµæ•°åˆ†å¸ƒ (å¯¹æ•°åˆ»åº¦)', fontsize=16)
plt.xlabel('æƒ…æ„Ÿç±»åˆ«', fontsize=12)
plt.ylabel('ç‚¹èµæ•° (Log Scale)', fontsize=12)
plt.legend(title='æ‰‹æœºå“ç‰Œ')
plt.grid(True, which="both", ls="--", alpha=0.6)
# ä¿å­˜å›¾ç‰‡
plt.savefig(os.path.join(output_dir, '3_likes_vs_sentiment_boxplot.png'), dpi=300, bbox_inches='tight')
plt.show()

# --- 5. è¯„è®ºå…³é”®è¯åˆ†æï¼ˆè¯äº‘ï¼‰ ---
print("\n--- æ­£åœ¨ç”Ÿæˆå…³é”®è¯è¯äº‘... ---")
stopwords = set(
    ['çš„', 'äº†', 'æ˜¯', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'ä»¬', 'ä¹Ÿ', 'åœ¨', 'éƒ½', 'å°±', 'å’Œ', 'ç­‰', 'å•Š', 'å—', 'å§', 'è¿™ä¸ª',
     'é‚£ä¸ª', 'éå¸¸', 'å¾ˆ', 'æœ‰', 'æ²¡æœ‰', 'ä¼š', 'å¯ä»¥', 'è¦', 'è¯´', 'å¯¹', 'ä¸', 'ä½†', 'å¦‚æœ', 'å› ä¸º', 'æ‰€ä»¥', 'è¿˜æ˜¯',
     'å›å¤', 'è¯„è®º', 'ç‚¹èµ', 'æ”¯æŒ', 'å–œæ¬¢', 'ä½¿ç”¨', 'ä½“éªŒ', 'æ„Ÿè§‰', 'æ‰‹æœº', 'å“ç‰Œ', 'é£“é£', 'ä»€ä¹ˆ', 'å¥½', 'å·®', 'èµ', 'å·®è¯„',
     'å°±æ˜¯', 'æ„Ÿè§‰', 'çœŸçš„', 'çœŸçš„å¾ˆ', 'çœŸçš„ä¸é”™', 'çœŸçš„å¥½', 'çœŸçš„å·®', 'doge', 'å“ˆå“ˆ', 'å“ˆå“ˆå“ˆ', 'å“ˆå“ˆå“ˆå“ˆ', 'å“ˆå“ˆå“ˆå“ˆ',
     'è§‰å¾—', 'ä½†æ˜¯', 'é‡‘ç®', 'çŸ¥é“', 'å¯èƒ½', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'æ€ä¹ˆä¼š', 'æ€ä¹ˆå¯èƒ½', 'æ€ä¹ˆä¼šè¿™æ ·', 'æ€ä¹ˆä¼šè¿™æ ·å‘¢', 'tim',
     'ç°åœ¨', 'ä¸€ä¸‹', 'ä¸æ˜¯', 'å·²ç»', 'è‡ªå·±', 'åƒç“œ', 'æ—¶å€™', 'ä¸€ä¸ª', 'è§†é¢‘', 'è¯„è®ºåŒº', 'è¯„è®º', 'ç›´æ¥', 'ä¸€ç›´', 'åªèƒ½'
     'è¿™ä¹ˆ', 'ä¸ä¼š', 'ç¡®å®', 'ä¸èƒ½', 'è¿™ä¹ˆ', 'å…¶ä»–', 'å…¶å®ƒ'])


def generate_wordcloud(text, title, filename):
    if CHINESE_FONT_PATH is None:
        print(f"æ— æ³•ç”Ÿæˆè¯äº‘ '{title}'ï¼Œå› ä¸ºæœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ã€‚")
        return

    word_list = jieba.lcut(text)
    words = [word for word in word_list if word not in stopwords and len(word) > 1]
    text_processed = " ".join(words)

    if not text_processed:
        print(f"'{title}' æ²¡æœ‰è¶³å¤Ÿçš„å†…å®¹ç”Ÿæˆè¯äº‘ã€‚")
        return

    wc = WordCloud(
        font_path=CHINESE_FONT_PATH,  # ä½¿ç”¨æˆ‘ä»¬æ‰¾åˆ°çš„å­—ä½“è·¯å¾„
        background_color='white',
        width=800,
        height=400,
        max_words=100,
        colormap='viridis'
    ).generate(text_processed)

    plt.figure(figsize=(10, 5))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis('off')
    plt.title(title, fontsize=16)
    # ä¿å­˜å›¾ç‰‡
    plt.savefig(os.path.join(output_dir, filename), dpi=300, bbox_inches='tight')
    plt.show()


# åä¸ºè´Ÿé¢è¯„è®ºå†…å®¹è¯äº‘
huawei_negative_content = " ".join(
    combined_df[(combined_df['brand'] == 'åä¸º') & (combined_df['sentiment'] == 'è´Ÿé¢')]['content'])
generate_wordcloud(huawei_negative_content, 'åä¸ºè´Ÿé¢è¯„è®ºå†…å®¹ å…³é”®è¯è¯äº‘', '4_wordcloud_huawei_negative_content.png')

# è‹¹æœè´Ÿé¢è¯„è®ºå†…å®¹è¯äº‘
apple_negative_content = " ".join(
    combined_df[(combined_df['brand'] == 'è‹¹æœ') & (combined_df['sentiment'] == 'è´Ÿé¢')]['content'])
generate_wordcloud(apple_negative_content, 'è‹¹æœè´Ÿé¢è¯„è®ºå†…å®¹ å…³é”®è¯è¯äº‘', '5_wordcloud_apple_negative_content.png')

# åä¸ºè¯„è®ºæ€»è®¡è¯äº‘
huawei_all_content = " ".join(combined_df[combined_df['brand'] == 'åä¸º']['content'])
generate_wordcloud(huawei_all_content, 'åä¸ºè¯„è®ºå†…å®¹ å…³é”®è¯è¯äº‘', '6_wordcloud_huawei_all_content.png')

# è‹¹æœè¯„è®ºæ€»è®¡è¯äº‘
apple_all_content = " ".join(combined_df[combined_df['brand'] == 'è‹¹æœ']['content'])
generate_wordcloud(apple_all_content, 'è‹¹æœè¯„è®ºå†…å®¹ å…³é”®è¯è¯äº‘', '7_wordcloud_apple_all_content.png')

# ç‚¹èµæ•°æ’åå‰100çš„åä¸ºè¯„è®ºè¯äº‘
huawei_top_likes_content = " ".join(
    combined_df[combined_df['brand'] == 'åä¸º'].nlargest(100, 'like_count')['content'])
generate_wordcloud(huawei_top_likes_content, 'åä¸ºç‚¹èµæ•°æ’åå‰100è¯„è®º å…³é”®è¯è¯äº‘', '8_wordcloud_huawei_top_likes_content.png')

# ç‚¹èµæ•°æ’åå‰100çš„è‹¹æœè¯„è®ºè¯äº‘
apple_top_likes_content = " ".join(
    combined_df[combined_df['brand'] == 'è‹¹æœ'].nlargest(100, 'like_count')['content'])
generate_wordcloud(apple_top_likes_content, 'è‹¹æœç‚¹èµæ•°æ’åå‰100è¯„è®º å…³é”®è¯è¯äº‘', '9_wordcloud_apple_top_likes_content.png')

print("\nğŸ‰ æ‰€æœ‰åˆ†æå’Œå›¾ç‰‡ç”Ÿæˆå·²å®Œæˆï¼")